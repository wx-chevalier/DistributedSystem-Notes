# 并发与并行

并发就是可同时发起执行的程序，指程序的逻辑结构；并行就是可以在支持并行的硬件上执行的并发程序，指程序的运⾏状态。换句话说，并发程序代表了所有可以实现并发行为的程序，这是一个比较宽泛的概念，并行程序也只是他的一个子集。并发是并⾏的必要条件；但并发不是并⾏的充分条件。并发只是更符合现实问题本质的表达，目的是简化代码逻辑，⽽不是使程序运⾏更快。要是程序运⾏更快必是并发程序加多核并⾏。

简言之，并发是同一时间应对（dealing with）多件事情的能力；并行是同一时间动手做（doing）多件事情的能力。

[![image.png](https://i.postimg.cc/N0jG91Pz/image.png)](https://postimg.cc/w1nYnszX)

并发是问题域中的概念——程序需要被设计成能够处理多个同时(或者几乎同时)发生的事件；一个并发程序含有多个逻辑上的独立执行块，它们可以独立地并行执行，也可以串行执行。而并行则是方法域中的概念——通过将问题中的多个部分并行执行，来加速解决问题。一个并行程序解决问题的速度往往比一个串行程序快得多，因为其可以同时执行整个任务的多个部分。并行程序可能有多个独立执行块，也可能仅有一个。

具体而言，早期的 Redis（6.0 版本后也引入了多线程） 会是一个很好地区分并发和并行的例子，它本身是一个单线程的数据库，但是可以通过多路复用与事件循环的方式来提供并发地 IO 服务。这是因为多核并行本质上会有很大的一个同步的代价，特别是在锁或者信号量的情况下。因此，Redis 利用了单线程的事件循环来保证一系列的原子操作，从而保证了即使在高并发的情况下也能达到几乎零消耗的同步。再引用下 Rob Pike 的描述：

> A single-threaded program can definitely provides concurrency at the IO level by using an IO (de)multiplexing mechanism and an event loop (which is what Redis does).

# 并发维度

## 线程级并发

从 20 世纪 60 年代初期出现时间共享以来，计算机系统中就开始有了对并发执行的支持；传统意义上，这种并发执行只是模拟出来的，是通过使一台计算机在它正在执行的进程间快速切换的方式实现的，这种配置称为单处理器系统。从 20 世纪 80 年代开始，多处理器系统，即由单操作系统内核控制的多处理器组成的系统采用了多核处理器与超线程（HyperThreading）等技术允许我们实现真正的并行。多核处理器是将多个 CPU 集成到一个集成电路芯片上：

![image](https://user-images.githubusercontent.com/5803001/52341286-21d58300-2a4d-11e9-85fe-5fe5f3894d66.png)

超线程，有时称为同时多线程（simultaneous multi-threading），是一项允许一个 CPU 执行多个控制流的技术。它涉及 CPU 某些硬件有多个备份，比如程序计数器和寄存器文件；而其他的硬件部分只有一份，比如执行浮点算术运算的单元。常规的处理器需要大约 20 000 个时钟周期做不同线程间的转换，而超线程的处理器可以在单个周期的基础上决定要执行哪一个线程。这使得 CPU 能够更好地利用它的处理资源。例如，假设一个线程必须等到某些数据被装载到高速缓存中，那 CPU 就可以继续去执行另一个线程。

## 指令级并发

在较低的抽象层次上，现代处理器可以同时执行多条指令的属性称为指令级并行。实每条指令从开始到结束需要长得多的时间，大约 20 个或者更多的周期，但是处理器使用了非常多的聪明技巧来同时处理多达 100 条的指令。在流水线中，将执行一条指令所需要的活动划分成不同的步骤，将处理器的硬件组织成一系列的阶段，每个阶段执行一个步骤。这些阶段可以并行地操作，用来处理不同指令的不同部分。我们会看到一个相当简单的硬件设计，它能够达到接近于一个时钟周期一条指令的执行速率。如果处理器可以达到比一个周期一条指令更快的执行速率，就称之为超标量（Super Scalar）处理器。

## 单指令、多数据

在最低层次上，许多现代处理器拥有特殊的硬件，允许一条指令产生多个可以并行执行的操作，这种方式称为单指令、多数据，即 SIMD 并行。例如，较新的 Intel 和 AMD 处理器都具有并行地对 4 对单精度浮点数（C 数据类型 float）做加法的指令。

# 同步、异步、阻塞、非阻塞

在并发与并行的基础概念之后，我们还需要了解同步、异步、阻塞与非阻塞这几个概念的关系与区别。

同步即执行某个操作开始后就一直等着按部就班的直到操作结束，异步即执行某个操作后立即离开，后面有响应的话再来通知执行者。从编程的角度来看，如果同步调用，则调用的结果会在本次调用后返回。如果异步调用，则调用的结果不会直接返回。会返回一个 Future 或者 Promise 对象来供调用方主动/被动的获取本次调用的结果。

![](https://s2.ax1x.com/2019/09/02/nCnJgK.png)

而阻塞与非阻塞在并发编程中，主要是从对于临界区公共资源或者共享数据竞态访问的角度来进行区分。某个操作需要的共享资源被占用了，只能等待，称为阻塞；某个操作需要的共享资源被占用了，不等待立即返回，并携带错误信息回去，期待重试，则称为非阻塞。

![](https://s2.ax1x.com/2019/09/02/nCu8aj.png)

值得一提的是，在[并发 IO](https://ngte-infras.gitbook.io/i/?q=并发%20IO) 的讨论中，我们还会出现同步非阻塞的 IO 模型，这是因为 IO 操作(read/write 系统调用)其实包含了发起 IO 请求与实际的 IO 读写这两个步骤。阻塞 IO 和非阻塞 IO 的区别在于第一步，发起 IO 请求的进程是否会被阻塞，如果阻塞直到 IO 操作完成才返回那么就是传统的阻塞 IO，如果不阻塞，那么就是非阻塞 IO。同步 IO 和异步 IO 的区别就在于第二步，实际的 IO 读写(内核态与用户态的数据拷贝)是否需要进程参与，如果需要进程参与则是同步 IO，如果不需要进程参与就是异步 IO。如果实际的 IO 读写需要请求进程参与，那么就是同步 IO；因此阻塞 IO、非阻塞 IO、IO 复用、信号驱动 IO 都是同步 IO。

# 并发级别

在实际的部署环境下，受限于 CPU 的数量，我们不可能无限制地增加线程数量，不同场景需要的并发需求也不一样；譬如秒杀系统中我们强调高并发高吞吐，而对于一些下载服务，则更强调快响应低时延。因此根据不同的需求场景我们也可以定义不同的并发级别：

- 阻塞：阻塞是指一个线程进入临界区后，其它线程就必须在临界区外等待，待进去的线程执行完任务离开临界区后，其它线程才能再进去。

- 无饥饿：线程排队先来后到，不管优先级大小，先来先执行，就不会产生饥饿等待资源，也即公平锁；相反非公平锁则是根据优先级来执行，有可能排在前面的低优先级线程被后面的高优先级线程插队，就形成饥饿

- 无障碍：共享资源不加锁，每个线程都可以自有读写，单监测到被其他线程修改过则回滚操作，重试直到单独操作成功；风险就是如果多个线程发现彼此修改了，所有线程都需要回滚，就会导致死循环的回滚中，造成死锁

- 无锁：无锁是无障碍的加强版，无锁级别保证至少有一个线程在有限操作步骤内成功退出，不管是否修改成功，这样保证了多个线程回滚不至于导致死循环

- 无等待：无等待是无锁的升级版，并发编程的最高境界，无锁只保证有线程能成功退出，但存在低级别的线程一直处于饥饿状态，无等待则要求所有线程必须在有限步骤内完成退出，让低级别的线程有机会执行，从而保证所有线程都能运行，提高并发度。

# 量化模型

多线程不意味着并发，但并发肯定是多线程或者多进程；多线程存在的优势是能够更好的利用资源，有更快的请求响应。但是我们也深知一旦进入多线程，附带而来的是更高的编码复杂度，线程设计不当反而会带来更高的切换成本和资源开销。如何衡量多线程带来的效率提升呢，我们需要借助两个定律来衡量。

## Amdahl 定律

Amdahl 定律可以用来计算处理器平行运算之后效率提升的能力，其由 Gene Amdal 在 1967 年提出；它描述了在一个系统中，基于可并行化和串行化的组件各自所占的比重，程序通过获得额外的计算资源，理论上能够加速多少。任何程序或算法可以按照是否可以被并行化分为可以被并行化的部分 `1 - B` 与不可以被并行化的部分 B，那么根据 Amdahl 定律，不同的并行因子的情况下程序的总执行时间的变化如下所示：

![](https://coding.net/u/hoteam/p/Cache/git/raw/master/2017/8/3/2321312312.png)

如果 F 是必须串行化执行的比重，那么 Amdahl 定律告诉我们，在一个 N 处理器的机器中，我们最多可以加速：

![](https://coding.net/u/hoteam/p/Cache/git/raw/master/2017/8/3/111111111.png)

当 N 无限增大趋近无穷时，speedup 的最大值无限趋近 `1/F`，这意味着一个程序中如果 50% 的处理都需要串行进行的话，speedup 只能提升 2 倍(不考虑事实上有多少线程可用)；如果程序的 10% 需要串行进行，speedup 最多能够提高近 10 倍。

![](http://hi.csdn.net/attachment/201004/22/0_1271944737VpZC.gif)

Amdahl 定律同样量化了串行化的效率开销。在拥有 10 个处理器的系统中，程序如果有 10% 是串行化的，那么最多可以加速 5.3 倍(53 ％的使用率)，在拥有 100 个处理器的系统中，这个数字可以达到 9.2(9 ％的使用率)。这使得无效的 CPU 利用永远不可能到达 10 倍。下图展示了随着串行执行和处理器数量变化，处理器最大限度的利用率的曲线。随着处理器数量的增加，我们很明显地看到，即使串行化执行的程度发 生细微的百分比变化，都会大大限制吞吐量随计算资源增加。

Amdahl 定律旨在说明，多核 CPU 对系统进行优化时，优化的效果取决于 CPU 的数量以及系统中的串行化程序的比重；如果仅关注于提高 CPU 数量而不降低程序的串行化比重，也无法提高系统性能。

# Gustafson

系统优化某部件所获得的系统性能的改善程度，取决于该部件被使用的频率，或所占总执行时间的比例。
