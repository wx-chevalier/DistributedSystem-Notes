# 5. 复制: 弱一致性模型协议

我们已经看到在越来越多的失效案例中使用单副本一致性协议是切实可行的，现在让我们转移注意力，假设一旦放弃对单副本一致性的要求，那么就会打开新的世界。

总的来说，很难找到一个单一维度来定义或描述允许副本出现差异的协议。大多数这类协议都是高可用的，关键问题是，尽管在节点或网络故障时，副本可能会出现差异，但最终用户是否认为这些保障、抽象和 API 对于他们来说有用。

为什么弱一致性系统没有不流行？

正如我在引言中所说，我认为分布式编程的很多内容都是关于处理分布式两个因素所带来的影响：

- 信息以光速传播
- 独立事物，独立失败

对信息传播速度的限制所带来的影响是，每个节点都是独特而不同的。在单个节点上的计算是容易的，因为一切都以可预测的全局总序发生。而在一个分布式系统上的计算是困难的，因为不存在一个全局总序。

在很长的一段时间里（几十年的研究），我们通过引入全局总序来解决这个问题。我已经讨论了许多方法，在没有自然产生的总序的情况下可以通过创建顺序（以容错的方式）来实现强一致性。

当然，问题是按顺序执行的成本很高。尤其是在需要保持系统可用的大规模互联网系统中这种情况尤其会突出。一个强制执行强一致性的系统并不像一个分布式系统：它的行为像一个单一的系统，这对分区期间的可用性是不利的。

此外，对于每一次操作，往往必须联系大多数节点--而且往往不只是一次，而是两次（正如你在关于 2PC 的讨论中所看到的那样）。这在需要在地理上分布的系统中尤其痛苦，因为这些系统需要为全球用户群提供足够的性能。

所以，默认表现为单一系统或许并不可取。

也许我们想要的是这样一个系统，我们可以在其中编写不使用昂贵的协调机制，但又能返回一个"可用"值的代码。我们不会有一个统一的结果，而是会允许不同的副本间相互有差异--既要保持运行的效率，又要分区容错--然后尝试找到一种方式来处理副本间的差异。

最终的一致性表达了这样的想法：节点之间可以在一段时间内相互有差异，但最终它们会在值上达成一致。

在使用最终一致性的系统中，有两种类型的系统设计：

_最终一致性与概率保证_。这种类型的系统可以在以后的某个时间点检测到冲突的写入，但并不能保证最终结果等同于按正确顺序执行后的结果。换句话说，冲突的更新有时会导致用一个较旧的值覆盖一个较新的值，在正常的操作过程中（或者在分区过程中），可能会出现一些异常情况。

近年来，单副本一致性的系统设计中，最有影响力的是 Amazon 的 Dynamo，我将以提供最终一致性与概率保证的系统为例进行讨论。

_最终一致性与强保证_。这种类型的系统保证结果收敛到一个共同的值，相当于按正确的顺序执行。换句话说，这类系统不会产生任何异常的结果，在没有任何协调的情况下，你可以构建相同服务的副本，这些副本可以以任何模式进行通信，以任何顺序接收更新，只要它们都能看到相同的信息，它们最终会在最终结果上达成一致。

CRDT's（convergent replicated data types）是一种数据类型，即使有网络延迟、分区和消息重新排序等情况，但其仍能保证收敛到相同的值。它的收敛性是可证明，但可以实现为 CRDT's 的数据类型是有限的。

CALM（consistency as logical monotonicity）猜想是同一原理的另一种表达方式：它将逻辑单调性等同于收敛性。如果我们可以断定某件事情在逻辑上是单调的，那么它在没有协调的情况下运行也是安全的。汇总分析--特别是应用于 Bloom 编程语言的汇总分析--可以用来指导程序员决定何时何地使用来自强一致性系统的协调技术，以及何时可以安全地执行而无需协调。

## 协调不同作业单

一个不执行单副本一致性的系统是什么样的呢？让我们试着通过几个例子来让这个问题变得更加具体。

也许，不强制执行单副本一致性的系统最明显的特征是，它们允许副本相互差异。这意味着没有严格定义的通信模式：副本可以相互差异，但又可以继续可用并接受写入。

让我们想象一个由三个副本组成的系统，其中每个副本都与其他副本彼此分区。例如，这些副本可能在不同的数据中心，由于某种原因无法通信。在分区期间，每个副本都保持可用，接受某组客户端的读写：

```
[Clients]   - > [A]

--- Partition ---

[Clients]   - > [B]

--- Partition ---

[Clients]   - > [C]
```

一段时间后，分区恢复正常，副本服务器开始交换信息。它们从不同的客户端接收到了不同的更新，并且相互之间产生了数据差异，所以需要进行某种合并。我们希望发生的是，所有的副本都趋于相同的结果。

```
[A] \
    --> [merge]
[B] /     |
          |
[C] ----[merge]---> result
```

思考具有弱一致性保证的系统的另一种方式是想象一组客户端按照某种顺序向两个副本发送消息。由于没有协调协议强制执行单个总序，消息可能会以不同的顺序在两个副本上得到传递。

```
[Clients]  --> [A]  1, 2, 3
[Clients]  --> [B]  2, 3, 1
```

这实质上就是我们需要协调协议的原因。举例来说，假设我们正在尝试连接一个字符串，消息 1、2 和 3 中的操作是：

```
1: { operation: concat('Hello ') }
2: { operation: concat('World') }
3: { operation: concat('!') }
```

然后，在没有协调的情况下，A 会产生"Hello World!"，B 会产生"World!Hello "。

```
A: concat(concat(concat('', 'Hello '), 'World'), '!') = 'Hello World!'
B: concat(concat(concat('', 'World'), '!'), 'Hello ') = 'World!Hello '
```

当然，这是不正确的。同样，我们希望发生的情况是，副本达成同一结果。

牢记这两个例子，我们先看看 Amazon 的 Dynamo，建立一个基准线，然后讨论一些构建弱一致性保证系统的新颖方法，比如 CRDT 的和 CALM 定理。

## Amazon's Dynamo

Amazon 的 Dynamo 系统设计（2007 年）可能是最著名的只提供了弱一致性保证，但却有高可用性的系统。它是许多其他现实世界系统的基础，包括 LinkedIn 的 Voldemort，Facebook 的 Cassandra 和 Basho 的 Riak。

Dynamo 是一个最终一致性的、高可用的键值存储系统。一个键值存储系统就像一个大的哈希表：客户端可以通过 `set(key, value)` 设置值，并使用`get(key)`按键检索。一个 Dynamo 集群由 N 个对等节点组成；每个节点都有一组键值，由它负责存储。

Dynamo 优先考虑可用性而不是一致性；它不提供单副本一致性保证。相反，当值被写入时，副本间可能会有差异；当一个键被读取时，有一个读取协调阶段，试图在将值返回给客户端之前协调副本之间的差异。

对于 Amazon 上的许多功能来说，避免运行中断比确保数据完全一致更重要，因为运行中断会导致业务及信誉损失。此外，如果数据不是特别重要，那么弱一致性的系统可以以较低的成本提供比传统 RDBMS 更好的性能和更高的可用性。

由于 Dynamo 是一个完整的系统设计，除了核心的复制任务之外，还有很多不同的部分需要关注。下图说明了一些任务；特别是，如何将路由写到一个节点并写入多个副本。

```
[ Client ]
    |
( Mapping keys to nodes )
    |
    V
[ Node A ]
    |     \
( Synchronous replication task: minimum durability )
    |        \
[ Node B]  [ Node C ]
    A
    |
( Conflict detection; asynchronous replication task:
  ensuring that partitioned / recovered nodes recover )
    |
    V
[ Node D]
```

看完了最初是如何写操作之后，我们再来看看如何检测冲突，以及异步副本同步任务。之所以需要这个任务，是因为在高可用性设计中，节点可能会暂时不可用（宕机或分区）。副本同步任务可以确保节点在发生故障后也能相当迅速地赶上。

### 一致性哈希

无论我们是读还是写，首先需要做的是定位数据在系统上的位置。这需要某种类型的键到节点的映射。

在 Dynamo 中，键映射到节点使用了一种被称为[一致性哈希](https://github.com/mixu/vnodehash)的技术（我不会详细讨论）。其主要思想是，通过对客户端的简单计算，可以将一个键映射到一组负责该键的节点上。这意味着客户端可以直接定位键，而不必向系统查询每个键的位置；这节省了系统资源，因为使用哈希通常比执行远程过程调用更快。

### Partial Quorums

一旦我们知道一个键应该存储在哪里，我们就需要做一些工作来持久化这个值。这是一项同步任务；我们之所以会立即将值写入多个节点，是为了提供更高的持久性（例如保护节点不会立即失效）。

就像 Paxos 或 Raft 一样，Dynamo 也使用 Quorum 协议进行复制。然而，Dynamo 的 Quorum 协议是粗放的（partial），而不是严格的（majority）。

从非正式的角度来说，严格的基于 Quorum 协议的系统是指系统中任意两个 quorums（集）属性重叠的 Quorum 系统。要求在接受一个更新之前，需要多数节点投票，确保只接受单个历史记录，因为每个采用多数决 Quorum 机制的系统都必须在至少一个节点中重叠。例如，Paxos 就是依靠这一特性。

在 Partial Quorums 中无需这个属性；这意味着不需要多数决，同时采用 Partial Quorum 协议的不同子集中可能包含同一数据的不同版本。用户可以选择写入和读取的节点数量：

- 用户可以选择写成功所需的节点数量（W-of-N）
- 用户可以指定在读取过程中所需的节点数量（R-of-N）

`W`和 `R` 分别规定了写与读参与所需的节点数量。向更多节点写入会使写入速度减慢，但减少了值丢失的概率；从更多节点读取则会增加读取到最新值的概率。

通常的建议是 `R + W > N`，因为这意味着读和写至少在一个节点上重叠——使得返回一个旧值的可能性降低。一个典型的配置是`N = 3`（例如每个值总共有三个副本）；这意味着用户可以在以下两者之间选择：

```
 R = 1, W = 3;
 R = 2, W = 2 or
 R = 3, W = 1
```

更一般地说，同样假设 `R + W > N`：

- `R = 1`, `W = N`: 读取快, 写入慢
- `R = N`, `W = 1`: 写入快, 读取慢
- `R = N/2` and `W = N/2 + 1`: 折衷

N 很少超过 3 个，因为保存海量数据的多副本是非常昂贵的!

正如我前面提到的，Dynamo 论文启发了许多其他类似的设计。它们都使用了相同的基于 Partial Quorums 协议的复制方法，但 N、W 和 R 的默认值不同：

- Basho 的 Riak (N = 3, R = 2, W = 2 default)
- Linkedin 的 Voldemort (N = 2 or 3, R = 1, W = 1 default)
- Apache 的 Cassandra (N = 3, R = 1, W = 1 default)

还有一个细节：当发送一个读或写请求时，是要求所有 N 个节点都响应（Riak），还是只要求满足最少的若干节点响应（如 R 或 W；Voldemort）。"向所有节点发送"的方式速度更快，对延迟的敏感度更低（因为它只等待 N 个节点中速度最快的 R 或 W），但效率也更低；而"向最少节点发送"的方式对延迟更敏感（因为与单个节点通信的延迟会导致总体操作延迟），但效率也更高（总体上消息/连接更少）。

当读和写的数量重叠时，例如(`R + W > N`)，会发生什么呢？具体来说，人们经常声称这将导致"强一致性"。

### R + W > N 是否等同于 “强一致性”？

答案是否定的

这个观点也并非完全错误：一个 `R + W > N` 的系统可以检测到读/写冲突，因为任何读取和写入都共享一个节点。如：至少有一个节点在这次选中的两个节点中重叠。

```
   1     2   N/2+1     N/2+2    N
  [...] [R]  [R + W]   [W]    [...]
```

这保证了在以后的读操作中可以看到以前写操作的结果。然而，这只在 N 中的节点永不改变的情况下才成立。因此，Dynamo 不符合条件，因为在 Dynamo 中，如果节点失效，集群成员会发生变化。

Dynamo 被设计为始终可写。它有一个处理节点故障的机制，当原来的服务器宕机时，会在负责某些键的节点集中增加一个不同的、不相关的服务器来处理这些节点故障。这意味着不再保证读与写的节点总是重叠的。即使是 `R = W = N` 也不符合条件，因为虽然节点总数大小等于 N，但在故障期间，这些节点可能会发生变化。具体来说，在分区过程中，如果无法达到足够数量的节点，Dynamo 将从不相关但可访问的节点中向分区中添加新的节点。

此外，Dynamo 处理分区的方式与执行强一致性模型的系统方式不同：即允许在分区的两边都进行写入，这意味着至少在一段时间内，系统不会作为一个单一的副本。所以称`R + W > N`为"强一致性"是有误导性的，保证只是概率性的——这不是强一致性所指的。

### 冲突检测与读取修复

允许副本差异的系统必须有一种方法来最终合并两个不同的值。正如在 Partial Quorums 方法中简单提到的，实现此目的的一种方法是在读取时检测冲突，然后应用一些冲突解决方法。但是如何做到这一点呢？

一般来说，是通过补充一些元数据来跟踪一段数据的因果历史来完成的。客户端从系统中读取数据时必须保留元数据信息，向数据库写入数据时必须返回元数据值。

我们已经遇到过一种方法：向量钟可以用来表示一个值的历史。事实上，最初的 Dynamo 设计就是用这个方法来检测冲突。

然而，使用向量钟并不是唯一的选择。如果你看一下许多实际的系统设计，你可以通过查看它们所跟踪的元数据来推断出它们的工作方式

_无元数据_：当一个系统不跟踪元数据，只返回值时（例如通过客户端 API），它不能真正对并发写入做任何特殊的事情。一个常见的规则是，最后一个写入者获胜：换句话说，如果两个写入者同时写入，只有最慢的写入者的值会被保留下来。

_时间戳_：通常情况下，时间戳较大的值获胜。然而，如果没有仔细同步时间，就会发生许多奇怪的事情，来自系统故障的旧数据或因时钟过快导致覆盖较新的值。Facebook 的 Cassandra 是一个 Dynamo 变体，它使用时间戳而不是向量钟。

_版本号_：版本号可以避免因使用时间戳而导致的一些有关问题。请注意，当可能有多个历史记录时，能够准确跟踪因果关系的最小机制是向量钟，而不是版本号。

_向量钟_：使用向量钟，可以检测到并发的和过时的更新。这使得执行读取修复成为可能，尽管在某些情况下（并发更改）我们需要让客户端选择一个值。这是因为如果更改是并发的，而我们对数据一无所知（就像简单的键值存储的情况一样），那么询问客户端总比任意丢弃数据要好。

当要读取一个值时，客户端需要联系 N 个节点中的 R 个节点，并向他们询问一个键值所对应的最新值。客户端接收所有的响应，丢弃严格意义上的旧值（使用向量钟值来检测）。如果只有一个唯一的向量钟+值对，客户端就返回这个值。如果有多个同时被编辑过的向量钟+值对（例如不具有可比性），则返回所有这些值。

从上面可以看出，读取修复可能会返回多个值。这意味着客户端/应用程序开发人员必须偶尔处理这些情况，根据一些特定的使用情况标准来选取一个值。

此外，实际的向量钟系统的一个关键要素是不能让时钟永远增长——因此需要有一个程序，以安全的方式对时钟进行垃圾回收，以平衡容错性和存储要求。

### 副本同步: Gossip 与 Merkle 树

考虑到 Dynamo 系统设计对节点故障和网络分区的容错性，它需要一种方法来处理节点被分区后重新加入集群，或者当故障节点被替换以及部分恢复时。

副本同步用于在发生故障后使各节点达到最新状态，并用于定期同步副本之间的关系。

Gossip 是一种概率性的副本同步技术。通信的模式（如哪个节点联系哪个节点）不是事先确定的。相反，节点之间有一定的概率 `p` 来尝试同步。每隔 `t` 秒，每个节点会挑选一个节点进行通信。这提供了同步任务之外的额外机制（例如 Partial Quorums 的写入），使得副本更新。

Gossip 是可扩展的，而且没有单点故障，但只能提供概率保证。

为了使副本同步过程中的信息交换高效，Dynamo 使用了一种叫做 Merkle 树的技术，我就不详细介绍了。其关键思想是，一个数据存储可以在多个不同的粒度层次上进行哈希：根节点哈希代表整个内容，左节点的哈希代表其下左右子节点的内容，右节点相同，以此类推。

通过维护这种相当细粒度的哈希方法，节点可以更有效地比较它们的数据存储内容。一旦节点确定了哪些键具有不同的值，它们就会交换必要的信息，以使副本更新。

### 实际中的 Dynamo: 概率有界过时态 （probabilistically bounded staleness PBS）

以下几点几乎涵盖了 Dynamo 系统的设计：

- 一致性哈希来确定键的位置
- Partial Quorums 用于读写
- 通过向量钟来冲突检测和读取修复。
- 用 Gossip 同步副本

我们如何描述这样一个系统的行为？Bailis 等人在(2012)最近的一篇论文中描述了一种叫做[PBS](http://pbs.cs.berkeley.edu/)(概率有界过时态)的方法，使用模拟和从真实世界系统中收集的数据来描述此类系统的预期行为。

PBS 通过使用有关反熵（Gossip）率、网络延迟和本地处理延迟的信息来估计不一致程度，以估计读取一致性的预期水平。它已经在 Cassandra 中实现，时序信息被附加在其他消息上，并在蒙特卡洛模拟中根据这些信息的样本计算出一个估计值。

根据这篇论文，在正常操作过程中，最终一致的数据存储往往更快，可以在几十或几百毫秒内读取到一致的状态。下表说明了在 LinkedIn(SSD 和 15k RPM 磁盘)和 Yammer 上的实际时序数据上，给定不同的 `R` 和 `W` 的设置，对于 99.9%概率的一致读取所需的时间量：

![from the PBS paper](https://ngte-superbed.oss-cn-beijing.aliyuncs.com/book/Distributed-systems-for-fun-and-profit/pbs.png)

例如，在 Yammer 的情况下，从 `R=1`, `W=1`到`R=2`, `W=1` ，将数据不一致窗口期从 1364 ms 减少到 202 ms--同时保持读取延迟（32.6 ms）低于最快的严格定额（ `R=3`, `W=1`; 219.27 ms）。

更多详情，请看[PBS 网站](http://pbs.cs.berkeley.edu/)和相关文件。

## 无序编程

让我们回顾一下我们想要解决的各类情况的例子。第一个场景在分区后包含三个不同的服务器；分区恢复后，我们希望服务器收敛到相同的数值。Amazon 的 Dynamo 通过从 `N` 个节点中读取 `R` 个节点的数据，然后进行读取合并来实现这一点。

在第二个例子中，我们考虑了一个更具体的操作：字符串拼接。事实证明，没有已知的技术可以在不对操作施加顺序的情况下（例如没有昂贵的协调机制），使字符串拼接为相同的值。然而，有一些操作可以以任意顺序安全地应用，而简单的记录将无法做到这一点。正如 Pat Helland 所写的那样：

> ...以操作为中心的工作是可交换的(用正确的操作和正确的语义)，而简单的 READ/WRITE 语义不会使其自身具有交换性

例如，考虑用两种不同的方式实现一个简单的会计制度， 有`debit` 和 `credit` 两种业务的系统。

- 使用 `read` 和 `write` 直接操作记录
- 使用 `debit` 和 `credit` 操作整型数据类型

后者的实现需要更了解数据类型的内部结构，因此尽管操作被重新排序，它仍能保留操作的意图。借贷操作可以按任意顺序执行，最终结果是一样的：

```
100 + credit(10) + credit(20) = 130 and
100 + credit(20) + credit(10) = 130
```

然而，写一个固定的值则不能按任意顺序进行：如果重新排序，其中的一个写操作将会覆盖另一个：

```
100 + write(110) + write(130) = 130 but
100 + write(130) + write(110) = 110
```

让我们以本章开头的例子为例，但使用不同的操作。在这个场景中，客户端向两个节点发送消息，这两个节点看到的操作顺序不同：

```
[Clients]  --> [A]  1, 2, 3
[Clients]  --> [B]  2, 3, 1
```

Instead of string concatenation, assume that we are looking to find the largest value (e.g. MAX()) for a set of integers. The messages 1, 2 and 3 are:

我们不采用字符串拼接的方式，而是假设我们正在寻找一组整数的最大值（如 MAX()）。假设消息 1、2、3 是：

```
1: { operation: max(previous, 3) }
2: { operation: max(previous, 5) }
3: { operation: max(previous, 7) }
```

那么，在没有协调机制的情况下，A 和 B 最终都会收敛到 7，如：

```
A: max(max(max(0, 3), 5), 7) = 7
B: max(max(max(0, 5), 7), 3) = 7
```

在这两种情况下，两个副本看到的更新顺序不同，但我们能够以一种无论顺序是什么，但结果却相同的方式进行合并。由于我们使用了合并程序 (`max`) ，所以在这两种情况下，结果都会收敛到相同的答案。

不可能编写一个适用于所有数据类型的合并过程。在 Dynamo 中，值采用的是一个二进制 blob，所以最好的办法就是将其公开，并要求应用程序自己处理每个冲突。

然而，如果我们知道数据的类型比较特殊，那么处理这类数据的冲突就成为可能。 CRDT's 是为了提供结果始终收敛的数据类型而设计的一种数据结构，只要它们看到相同的操作集(以任意顺序)。

## CRDTs: 聚合复制数据类型

CRDT(convergent replicated datatypes)利用了关于特定数据类型上特定操作的交换律和结合律的知识。

为了使一组操作在副本偶尔才进行通信的环境中趋向于相同的值，这些操作需要与顺序无关，并且对(消息)复制/重发不敏感。因此，它们的操作需要是：

- 结合律 (`a+(b+c)=(a+b)+c`), 如何分组没有关系
- 交换律 (`a+b=b+a`), 应用的顺序也没关系
- 幂等性 (`a+a=a`), 重复操作没有关系

事实证明，这些结构在数学中是已知的，它们被称为接合 join [semilattices](http://en.wikipedia.org/wiki/Semilattice)或 meet [semilattices](http://en.wikipedia.org/wiki/Semilattice)。

[lattice](<http://en.wikipedia.org/wiki/Lattice_(order)>)是一个偏序集，它有一个明确的上界（上确界）和一个明确的下界（下确界）。semilattice 就像 lattice 一样，但是它只有一个明确的上界或下界。 join semilattice 是有明确的上界（上确界），meet semilattice 是有明确的下界（下确界）。

任何表示为 semilattice 的数据类型都可以实现为保证收敛的数据结构。例如，计算一组值的 `max()` ，只要所有的值最终都被接收，无论接收值的顺序如何，都会返回相同的结果，因为 `max()` 操作是符合结合律、交换律和幂等性的。

For example, here are two lattices: one drawn for a set, where the merge operator is `union(items)` and one drawn for a strictly increasing integer counter, where the merge operator is `max(values)`:

例如，这里有两个 lattices：一个是依据某集合绘制的，其中合并操作符是 `union(items)` ，另一个是依据某严格增加的整数计数器绘制的，其中合并操作符是 `max(values)`：

```
   { a, b, c }              7
  /      |    \            /  \
{a, b} {b,c} {a,c}        5    7
  |  \  /  | /           /   |  \
  {a} {b} {c}            3   5   7
```

有了可以表示为 semilattice 的数据类型，你就可以让副本以任何模式进行通信，并以任何顺序接收更新，只要它们都能看到相同的信息，它们最终会就结果达成一致。这是一个强大的属性，只要前提条件成立，就可以得到保证。

然而，将数据类型表示为 semilattice 常需要一定程度的说明。许多数据类型的操作实际上不是顺序独立的。例如，将某项添加到一个集合中符合结合律、交换律和幂等性的。然而，如果我们还允许从一个集合中删除项目，那么我们需要一些方法来解决这些冲突的操作，例如 `add(A)` 和 `remove(A)`。如果本地副本从未添加过某个元素，那么删除该元素是什么意思呢？这种解决方式必须以一种与顺序无关的方式来指定，有几种不同的选择，他们之间有不同的权衡。

这意味着一些熟悉的数据类型具有更特殊的实现，例如 CRDT 的实现，它进行了不同的折衷，以便以顺序无关的方式解决冲突。不同于用简单处理记录的键值存储（例如从系统的角度看值是不透明的二进制对象），使用 CRDT 的人必须使用正确的数据类型来避免异常。

可以指定为 CRDT 不同数据类型的一些例子：

- Counters
  - Grow-only Counter (merge = max(values); payload = single integer)
  - Positive-negative Counter (由两个计数器组成，一个负责增，另一个负责减)
- Registers
  - Last Write Wins Register (时间戳或版本号; merge = max(ts); payload = blob)
  - Multi-valued Register (向量钟; merge = take both)
- Sets
  - Grow-only Set (merge = union(items); payload = set; no removal)
  - Two-phase Set (由两个集合组成，一个集合用于添加，另一个用于删除；集合中的元素可以添加一次，也可以删除一次。`译者注：但值得注意的是两个集合中的元素只增加不删除，因此在删除集合中的元素不会消失，导致最终合并后已被删除的元素无法再次添加`)
  - Unique Set (两阶段集合的优化版本)
  - Last write wins Set (merge = max(ts); payload = set)
  - Positive-negative Set (集合中的每一项由一个 PN Counter 组成)
  - Observed-remove Set
- 图形和文本序列（请参见论文）

为了确保无异常操作，你需要为你的特定应用找到合适的数据类型——例如，如果你知道你只会删除一个项目一次，那么用 Two-phase Set 就可以了；如果你永远只会将项目添加到一个集合中，而永远不会删除它们，那么使用 Grow-only Set 就可以了。

并非所有的数据结构都有已知的 CRDT 实现，但在 Shapiro 等人最近（2011 年）的[调查论文](http://hal.inria.fr/docs/00/55/55/88/PDF/techreport.pdf)中，有针对 Booleans、Counters、Sets 、Registers 和 Graphs 的 CRDT 实现。

有趣的是，Register 的实现与键值存储使用的实现直接对应：Last Write Wins Register 使用时间戳或一些等价物，并简单地收敛到最大的时间戳值；Multi-valued Register 对应于 Dynamo 保留、公开和协调并发变更的策略。详细的内容，我推荐大家看看本章扩展阅读部分的论文

## CALM 定理

CRDT 数据结构是基于这样的认识，即可表达为 semilattices 的数据结构是收敛的。但是除非你只是实现一个数据存储，否则编程不仅仅是演化状态。

显然，顺序无关性是任何收敛计算的一个重要属性：如果接收数据项的顺序会影响计算的结果，那么就没有办法在不保证顺序的情况下执行计算。

然而，有许多编程模型中，语句的顺序并没有发挥重要作用。例如，在[MapReduce 模型](http://en.wikipedia.org/wiki/MapReduce)中，Map 和 Reduce 任务都被指定为需要在数据集上运行的无状态元组处理任务。关于数据如何以及以何种顺序路由到任务的具体决策并没有被明确指定，相反是由批处理作业调度器负责调度任务在集群上运行。

同样的，在 SQL 中，人们指定了查询，但没有指定如何执行查询。查询只是对任务的声明性描述，查询优化器的工作是找出一种有效的方式来执行查询（跨多台机器、数据库和表）。

当然，这些编程模型并不像通用编程语言那样宽松。MapReduce 任务需要在无环数据流程序中表示为无状态任务；SQL 语句可以执行相当复杂的计算，但是很多东西很难用它来表达。

然而，从这两个例子中可以清楚地看到，有许多类型的数据处理任务可以用声明式语言来表达的，在这种语言中，执行的顺序没有明确规定。在表达预期结果的同时，将语句的确切顺序留给优化器来决定的编程模型通常具有与顺序无关的语义。这意味着这类程序无需协调就可以执行，因为它们只取决于它们接收到的输入，但不一定取决于接收输入的特定顺序。

关键的一点是，这样的程序在没有协调的情况下*可能是*安全执行的。如果没有一个明确的规则来描述在没有协调的情况下什么是安全的，什么是不安全的，我们就不能在执行一个程序的同时还能确定结果是正确的。

这就是 CALM 定理的意义所在。CALM 定理是一种基于对逻辑单调性和最终一致性的有效形式（如汇总/收敛）之间的联系的认识。它指出，逻辑上单调的程序可以保证最终是一致的。

那么，如果我们知道某个计算在逻辑上是单调的，那么我们就知道它在没有协调的情况下执行也是安全的。

为了更好地理解这一点，我们需要将单调逻辑（或单调计算）与 [非单调逻辑](http://plato.stanford.edu/entries/logic-nonmonotonic/)（或非单调计算）进行对比。

- 单调性

  如果语句 `φ` 是一组以 `Γ` 为前提推导出的结论，那么它也可以从任何一组由 `Γ` 延伸出的前提 `Δ` 中推导出来。

大多数标准逻辑框架都是单调的：在诸如一阶逻辑这样的框架内做出的任何推论，一旦演绎有效，就不能被新的信息所否定。非单调逻辑是指该性质不成立的系统——换句话说，某些结论可以通过学习新知识而失效。

在人工智能界，非单调逻辑与[可废止推理](http://plato.stanford.edu/entries/reasoning-defeasible/)相关联--推理中，利用部分信息所做的断言可以被新知识所否定。例如，如果我们了解到 Tweety 是一只鸟，我们就会假设 Tweety 会飞；但如果我们后来了解到 Tweety 是一只企鹅，那么我们就必须修改我们的结论。

单调性涉及前提（或关于世界的事实）和结论（或关于世界的断言）之间的关系。在单调逻辑中，我们知道我们的结果是无回溯的：[单调性](http://en.wikipedia.org/wiki/Monotonicity_of_entailment)计算不需要重新计算或协调；答案会随着时间的推移变得更加准确。一旦我们知道 Tweety 是一只鸟（而且我们使用单调逻辑进行推理），我们就可以安全地得出 Tweety 会飞的结论，而且我们学到的任何东西都不能使这个结论失效。

虽然任何产生人性化结果的计算都可以被解释为对世界的断言（例如"foo"的值是"bar"），但很难确定基于冯-诺依曼机器编程模型中的计算是否是单调的，因为并不完全清楚事实和断言之间的关系，以及这些关系是否是单调的。

然而，有一些编程模型是可以确定单调性的。特别是[关系代数](http://en.wikipedia.org/wiki/Relational_algebra)(如 SQL 的理论基础)和[Datalog](http://en.wikipedia.org/wiki/Datalog)提供了具有高度表现力的语言，这些语言有很好理解的解释。

基本的 Datalog 和关系代数(即使是递归)都是已知单调性的。更具体地说，使用某一组基本运算符表示的计算是已知单调性的(选择、投影、自然连接、交叉积、联合和无否定的递归 Datalog)，而非单调性是通过使用更高级的运算符(否定、集差、除法、普遍量化、聚合)引入的。

这意味着在这些系统中使用大量运算符(如 map、filter、join、union、intersection)表示的计算在逻辑上是单调的；任何使用这些运算符的计算也是单调的，因此无需协调就可以安全运行。另一方面，使用否定和聚合的表达式在没有协调的情况下运行是不安全的。

重要的是要认识到非单调性与分布式系统中昂贵的操作之间的联系。具体来说，*分布式聚合*和*协调协议*都可以被认为是一种否定的形式。正如 Joe Hellerstein[所写的](http://www.eecs.berkeley.edu/Pubs/TechRpts/2010/EECS-2010-90.pdf)那样。

> 为了在分布式环境中建立否定谓词的准确性，评估策略计数必须从"0"开始以确定空值，并等待分布式计数过程明确结束。聚合是这一思想的概括。

and:

> 这种想法也可以从另一个角度来看。协调协议本身就是聚合的一种形式，因为它们需要投票。两阶段提交需要一致投票，Paxos 共识需要多数票 而拜占庭协议需要三分之二的多数票。等待需要计数。

如果能够以一种可以测试单调性的方式来表示我们的计算，那么我们就可以进行整个程序的静态分析，以检测程序中哪些部分最终是一致的，并且在没有协调的情况下可以安全运行（单调的部分）——而哪些部分不是（非单调的部分）。

请注意，这需要一种不同的语言，因为对于传统的编程语言来说，其核心是序列、选择和迭代，这些推论是很难做到的。这也是为什么要设计 Bloom 语言的原因。

## 非单调性有什么好处？

单调性和非单调性的区别很有意思。例如，将两个数字相加是单调性的，但在包含数字的两个节点上计算聚合就不是。这两者的区别是什么呢？其中一个是计算（添加两个数字），而另一个是断言（计算聚合）。

计算与断言有什么不同？让我们考虑一下"披萨是蔬菜吗？"这个问题。要回答这个问题，我们需要找到核心：什么时候可以推断出某件事是（或不是）真？

有几种可以接受的答案，每一种答案都对应着一组不同的假设，这些假设是关于我们所拥有的信息以及我们应该如何根据这些信息采取行动——我们已经在不同的情况下接受了不同的答案。

在日常推理中，我们会做出所谓的[开放世界假设*(open-world assumption)*](http://en.wikipedia.org/wiki/Open_world_assumption)：我们假设自己并不是什么都知道，因此不能从缺乏知识的情况下做出结论。也就是说，任何一句话都可能是真的、假的或未知的。

|                                | OWA + 单调逻辑  | OWA + 非单调逻辑 |
| ------------------------------ | --------------- | ---------------- |
| 能推导出 P(true)               | 能断言 P(true)  | 不能断言 P(true) |
| 能推导出 P(false)              | 能断言 P(false) | 不能断言 P(true) |
| 不能推导出 P(true) 或 P(false) | 未知            | 未知             |

当做出开放世界的假设时，我们只能安全地断言一些我们可以从已知的东西中推断出来的东西。我们关于世界的信息被假定为是不完整的。

我们先来看看单调推理的情况。在这种情况下，我们所拥有的任何（可能是不完整的）知识都不会通过学习新知识而失效。所以，如果我们可以根据一些推理推断出一句话是真的，假设"含有两汤匙番茄酱的东西是蔬菜"，"披萨含有两汤匙番茄酱"，那么我们就可以得出"披萨是蔬菜"的结论。同理，我们也能推断出一句话是假的。

然而，如果我们不能推导出任何东西--例如，我们所拥有的知识集包含客户信息，而没有任何关于比萨饼或蔬菜的信息--那么在开放世界的假设下，我们不得不说，我们不能得出任何结论。

对于非单调性的知识，我们现在知道的任何东西都有可能失效。因此，即使我们能从目前的知识中推断出真假，我们也不能安全地得出任何结论。

然而，在数据库背景下，以及在许多计算机科学应用中，我们更倾向于做出明确的结论。这意味着假设所谓的[封闭世界假设*(closed-world assumption)*](http://en.wikipedia.org/wiki/Closed_world_assumption)：任何不能被证明为真的东西都是假的。这意味着不需要明确声明是假的。换句话说，我们所拥有的事实数据库被假定为是完整的（最小的），因此，任何不在其中的东西都可以被假定为假的。

例如，根据 CWA 的规定，如果我们的数据库中没有旧金山和赫尔辛基之间的航班条目，那么我们可以有把握地得出结论，不存在这样的航班

我们还需要一件东西才能做出确定的断言：[逻辑周延](<http://en.wikipedia.org/wiki/Circumscription_(logic)>)。周延是一种形式化的猜想规则。领域周延推测已知实体是全部存在的。我们需要能够假设已知实体是全部存在的，才能得出确定的结论。

|                                | CWA + 逻辑周延 +单调逻辑 | CWA + 逻辑周延 +非单调逻辑 |
| ------------------------------ | ------------------------ | -------------------------- |
| 能推导出 P(true)               | 能断言 P(true)           | 能断言 P(true)             |
| 能推导出 P(false)              | 能断言 P(false)          | 能断言 P(false)            |
| 不能推导出 P(true) 或 P(false) | 能断言 P(false)          | 能断言 P(false)            |

特别是，非单调推理需要这种假设。只有当我们假设我们拥有完整的信息时，我们才能做出有把握的断言，因为额外的信息可能会使我们的断言失效。

这在实践中意味着什么呢？首先，单调逻辑只要能推导出一句话是真的（或假的），就能得出明确的结论。第二，非单调逻辑需要一个额外的假设：已知实体是包含全部的。

那么，为什么表面上等价的两个运算是不同的？为什么两个数相加是单调的，而计算两个节点上的聚合就不是呢？因为聚合不仅要计算出一个和，还要断言它已经看到了所有的值。而保证这一点的唯一方法就是跨节点协调，并保证执行计算的节点真的看到了系统内的所有值。

因此，为了处理非单调性，人们需要使用分布式协调来确保只有在知道所有信息后才进行断言，或者在进行断言时要注意结论以后可能会失效。

出于表达性的原因，处理非单调性很重要。这归根结底是要能够表达非单调性的事物，例如，能够说某列的总和是 X 就很好，这说明系统必须检测到这种计算需要一个全局协调边界，以确保我们已经看到了所有的实体。

纯粹的单调系统是很少见的。似乎大多数应用程序即使在数据不完整的情况下，也是在封闭世界的假设下运行的，而我们人类对此是没有意见的。当一个数据库告诉你，旧金山和赫尔辛基之间不存在直飞航班时，你可能会将其视为"根据这个数据库，不存在直飞航班"，但你并不排除现实中这种航班仍然存在的可能性。

真的，这个问题只有在副本可能出现差异的时候才会变得有趣（例如在分区期间或由于正常运行期间的延迟）。那么就需要更具体的考虑：答案是仅仅基于当前节点，还是基于系统的整体。

此外，由于非单调性是由作出断言引起的，因此，许多计算可以进行很长时间，并且只在将一些结果或断言传递给第三方系统或最终用户时才应用协调，这似乎是合理的。当然，如果这些读写操作只是一个长期运行的计算的一部分，那么系统内的每一个读写操作就没有必要强制执行一个总顺序。

## Bloom 语言

[Bloom 语言](http://www.bloom-lang.net/)是一种旨在利用 CALM 定理而设计的语言。它是一个 Ruby DSL，它的形式基础是一种叫做 Dedalus 的时态逻辑编程语言。

在 Bloom 中，每个节点都有一个由 Collections 和 Lattices 组成的数据库。程序被表示为一组无序语句，这些语句与 Collections（事实集）和 Lattices（CRDTs）交互。语句默认是无序的，但也可以写非单调函数。

参考一下[Bloom 网站](http://www.bloom-lang.net/)和[教程](https://github.com/bloom-lang/bud/tree/master/docs)，了解更多关于 Bloom 的信息

---

## 扩展阅读

#### CALM 定理, 汇总分析 与 Bloom

[Joe Hellerstein's talk @RICON 2012](http://vimeo.com/53904989) is a good introduction to the topic, as is [Neil Conway's talk @Basho](http://vimeo.com/45111940). For Bloom in particular, see [Peter Alvaro's talk@Microsoft](http://channel9.msdn.com/Events/Lang-NEXT/Lang-NEXT-2012/Bloom-Disorderly-Programming-for-a-Distributed-World).

- [The Declarative Imperative: Experiences and Conjectures in Distributed Logic](http://www.eecs.berkeley.edu/Pubs/TechRpts/2010/EECS-2010-90.pdf) - Hellerstein, 2010
- [Consistency Analysis in Bloom: a CALM and Collected Approach](http://db.cs.berkeley.edu/papers/cidr11-bloom.pdf) - Alvaro et al., 2011
- [Logic and Lattices for Distributed Programming](http://db.cs.berkeley.edu/papers/UCB-lattice-tr.pdf) - Conway et al., 2012
- [Dedalus: Datalog in Time and Space](http://db.cs.berkeley.edu/papers/datalog2011-dedalus.pdf) - Alvaro et al., 2011

#### CRDTs

[Marc Shapiro's talk @ Microsoft](http://research.microsoft.com/apps/video/dl.aspx?id=153540) is a good starting point for understanding CRDT's.

- [CRDTs: Consistency Without Concurrency Control](http://hal.archives-ouvertes.fr/docs/00/39/79/81/PDF/RR-6956.pdf) - Letitia et al., 2009
- [A comprehensive study of Convergent and Commutative Replicated Data Types](http://hal.inria.fr/docs/00/55/55/88/PDF/techreport.pdf), Shapiro et al., 2011
- [An Optimized conflict-free Replicated Set](http://arxiv.org/pdf/1210.3368v1.pdf) - Bieniusa et al., 2012

#### Dynamo; PBS; 乐观复制

- [Dynamo: Amazon’s Highly Available Key-value Store](http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf) - DeCandia et al., 2007
- [PNUTS: Yahoo!'s Hosted Data Serving Platform](http://scholar.google.com/scholar?q=PNUTS:+Yahoo!'s+Hosted+Data+Serving+Platform) - Cooper et al., 2008
- [The Bayou Architecture: Support for Data Sharing among Mobile Users](http://scholar.google.com/scholar?q=The+Bayou+Architecture%3A+Support+for+Data+Sharing+among+Mobile+Users) - Demers et al. 1994
- [Probabilistically Bound Staleness for Practical Partial Quorums](http://pbs.cs.berkeley.edu/pbs-vldb2012.pdf) - Bailis et al., 2012
- [Eventual Consistency Today: Limitations, Extensions, and Beyond](https://queue.acm.org/detail.cfm?id=2462076) - Bailis & Ghodsi, 2013
- [Optimistic replication](http://www.ysaito.com/survey.pdf) - Saito & Shapiro, 2005
