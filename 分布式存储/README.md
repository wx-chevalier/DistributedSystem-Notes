![](https://i.postimg.cc/Z56JHk17/image.png)

# 分布式系统

随着移动互联网的发展智能终端的普及，计算机系统早就从单机独立工作过渡到多机器协作工作。计算机以集群的方式存在，按照分布式理论的指导构建出庞大复杂的应用服务，也已经深入人心。分布式（Distributed）是指在多台不同的服务器中部署不同的服务模块，通过远程调用协同工作，对外提供服务。集群（Cluster）是指在多台不同的服务器中部署相同应用或服务模块，构成一个集群，通过负载均衡设备对外提供服务。

本篇主要讨论分布式系统核心理论的相关内容。

![分布式系统思维脑图](https://i.postimg.cc/hPpjxqR9/Distributed-System.png)

# 分布式系统定义

典型的集中式系统即某个带多个终端的主机，终端仅负责数据的录入和输出，而没有有数据处理能力，并且运算、存储等全部在主机上进行。传统的银行系统、大型企业、科研单位、军队、政府等，存在着大量的这种集中式的系统。集中式系统的最大的特点就是部署结构非常简单，底层一般采用从 IBM、HP 等厂商购买到的昂贵的大型主机。因此无需考虑如何对服务进行多节点的部署，也就不用考虑各节点之间的分布式协作问题。但是，由于采用单机部署。很可能带来系统大而复杂、难于维护、发生单点故障、扩展性差等问题。

分布式系统中最基础的单元就是节点与网络，节点就是能提供单位服务的逻辑计算资源的集合，网络则将节点聚合起来，形成可协同工作的有机系统。传统的节点也就是一台单体的物理机，所有的服务都揉进去包括服务和数据库；随着虚拟化的发展，单台物理机往往可以分成多台虚拟机，实现资源利用的最大化，节点的概念也变成单台虚拟机上面服务；近几年容器技术逐渐成熟后，服务已经彻底容器化，也就是节点只是轻量级的容器服务。

网络将节点联接起来，但是网络也带来了一系列的问题。网络消息的传播有先后，消息丢失和延迟是经常发生的事情，典型的网络模式有如下三种：

- 同步网络：节点同步执行，消息延迟有限，高效全局锁
- 半同步网络：锁范围放宽
- 节点独立执行：消息延迟无上限，无全局锁，部分算法不可行

## 分布式系统特性

在分布式系统概念与设计一书中，对分布式系统做了如下定义：分布式系统是一个硬件或软件组件分布在不同的网络计算机上，彼此之间仅仅通过消息传递进行通信和协调的系统。简单来说就是一群独立计算机集合共同对外提供服务，但是对于系统的用户来说，就像是一台计算机在提供服务一样。分布式意味着可以采用更多的普通计算机(相对于昂贵的大型机)组成分布式集群对外提供服务。计算机越多，CPU、内存、存储资源等也就越多，能够处理的并发访问量也就越大。

从分布式系统的概念中我们知道，各个主机之间通信和协调主要通过网络进行，所以，分布式系统中的计算机在空间上几乎没有任何限制，这些计算机可能被放在不同的机柜上，也可能被部署在不同的机房中，还可能在不同的城市中，对于大型的网站甚至可能分布在不同的国家和地区。这种分布性能够有效规避单点故障，即单个点发生故障的时候会波及到整个系统或者网络，从而导致整个系统或者网络的瘫痪。

标准的分布式系统会具备以下特性：

- 分布式系统中的多台计算机之间在空间位置上可以随意分布，系统中的多台计算机之间没有主、从之分，即没有控制整个系统的主机，也没有受控的从机。

- 系统资源被所有计算机共享。每台计算机的用户不仅可以使用本机的资源，还可以使用本分布式系统中其他计算机的资源，包括 CPU、文件、打印机等。

- 系统中的若干台计算机可以互相协作来完成一个共同的任务，或者说一个程序可以分布在几台计算机上并行地运行。

- 系统中任意两台计算机都可以通过通信来交换信息。

## 分布式系统应用

分布式系统的常见应用包括了：

- 分布式应用和服务：将应用和服务进行分层和分割，然后将应用和服务模块进行分布式部署。这样做不仅可以提高并发访问能力、减少数据库连接和资源消耗，还能使不同应用复用共同的服务，使业务易于扩展。

- 分布式静态资源：对网站的静态资源如 JS、CSS 、图片等资源进行分布式部署可以减轻应用服务器的负载压力，提高访问速度。

- 分布式文件系统：单台计算机的存储始终有上限，随着网络的出现，多台计算机协作存储文件的方案也相继被提出来。最早的分布式文件系统其实也称为网络文件系统，现代分布式文件系统则出自由 The Google File System 这篇论文奠定了分布式文件系统的基础。几个常用的文件系统譬如 HDFS, FastDFS, CephmooseFS 等。

- 分布式数据库：大型网站常常需要处理海量数据，单台计算机往往无法提供足够的内存空间，可以对这些数据进行分布式存储。传统关系型数据库为了兼顾事务和性能的特性，在分布式方面的发展有限，非关系型数据库摆脱了事务的强一致性束缚，达到了最终一致性的效果，从而有了飞跃的发展，NoSql(Not Only Sql)也产生了多个架构的数据库类型，包括 KV，列式存储，文档类型等。

- 消息中间件：分布式消息队列系统是消除异步带来一系列的复杂步骤的一大利器，多线程高并发场景先我们常常要谨慎的去设计业务代码，来保证多线程并发情况下不出现资源竞争导致的死锁问题。而消息队列以一种延迟消费的模式将异步任务都存到队列，然后再逐个消化。

- 分布式计算：随着计算技术的发展，有些应用需要非常巨大的计算能力才能完成，如果采用集中式计算，需要耗费相当长的时间来完成。分布式计算将该应用分解成许多小的部分，分配给多台计算机进行处理。这样可以节约整体计算时间，大大提高计算效率。分布式计算系统在场景上分为离线计算，实时计算和流式计算。

和集中式系统相比，分布式系统的性价比更高、处理能力更强、可靠性更高、也有很好的扩展性。但是，分布式在解决了网站的高并发问题的同时也带来了一些其他问题。首先，分布式的必要条件就是网络，这可能对性能甚至服务能力造成一定的影响。其次，一个集群中的服务器数量越多，服务器宕机的概率也就越大。另外，由于服务在集群中分布是部署，用户的请求只会落到其中一台机器上，所以，一旦处理不好就很容易产生数据一致性问题。

# 常见术语

- 异步：牛津词典把“asynchronous（异步的）”定义为“不同时存在或发生的”。在本宣言的上下文中， 我们的意思是： 在来自客户端的请求被发送到了服务端之后， 对于该请求的处理可以发生这之后的任意时间点。对于发生在服务内部的执行过程， 客户端不能直接对其进行观察， 或者与之同步。这是同步处理（synchronous processing）的反义词， 同步处理意味着客户端只能在服务已经处理完成该请求之后， 才能恢复它自己的执行。

- 回压：当某个组件正竭力维持响应能力时， 系统作为一个整体就需要以合理的方式作出反应。对于正遭受压力的组件来说， 无论是灾难性地失败， 还是不受控地丢弃消息， 都是不可接受的。既然它既不能（成功地）应对（压力）， 又不能（直接地）失败， 那么它就应该向其上游组件传达其正在遭受压力的事实， 并让它们（该组件的上游组件）降低负载。这种回压（back-pressure）是一种重要的反馈机制， 使得系统得以优雅地响应负载， 而不是在负载下崩溃。回压可以一路扩散到（系统的）用户， 在这时即时响应性可能会有所降低， 但是这种机制将确保系统在负载之下具有回弹性 ， 并将提供信息，从而允许系统本身通过利用其他资源来帮助分发负载，参见弹性。

- 批量处理：当前计算机为反复执行同一项任务而进行了优化： 在（CPU 的）时钟频率保持不变的情况下， 指令缓存和分支预测增加了每秒可以被处理的指令数。这就意味着，快速连续地将不同的任务递交给相同的 CPU 核心，将并不能获益于本有可能得到的完全（最高利用率的）性能： 如果有可能，我们应该这样构造应用程序， 它的执行逻辑在不同的任务之间交替的频率更低。这就意味着可以成批地处理一组数据元素， 这也可能意味可以在专门的硬件线程（指 CPU 的逻辑核心）上执行不同处理步骤。同样的道理也适用于对于需要同步和协调的外部资源的使用。当从单一线程（即 CPU 核心）发送指令， 而不是从所有的 CPU 核心争夺带宽时， 由持久化存储设备所提供的 IO 带宽将可以得到显著提高。使用单一入口的额外的效益，即多个操作可以被重新排序， 从而更好地适应设备的最佳访问模式（当今的存储设备的线性存取性能要优于随机存取的性能）。此外， 批量处理还提供了分摊昂贵操作（如 IO）或者昂贵计算的成本的机会。例如， 将多个数据项打包到同一个网络数据包或者磁盘存储块中， 从而提高效能并降低使用率。

- 组件：我们所描述的是一个模块化的软件架构， 它（实际上）是一个非常古老的概念， 参见 Parnas（1972）。我们使用“组件（component）”（参见 C.2.8）这个术语， 因为它和“隔间（compartment）”联系紧密， 其意味着每个组件都是自包含的、封闭的并和其他的组件相隔离。这个概念首先适用于系统的运行时特征， 但是它通常也会反映在源代码的模块化结构中。虽然不同的组件可能会使用相同的软件模块来执行通用的任务， 但是定义了每个组件的顶层行为的程序代码则是组件本身的一个模块。组件边界通常与问题域中的有界上下文（BoundedContext）紧密对齐。这意味着，系统设计倾向于反应问题域， 并因此在保持隔离的同时也更加容易演化。消息协议为多个有界上下文(组件)之间提供了自然的映射和通信层。

- 委托：将任务异步地委托给另一个#组件意味着该任务将会在另一个组件的上下文中被执行， 举几个可能的情况： 这个被委托的内容甚至可能意味着运行在不同的错误处理上下文里，属于不同的线程，来自不同的进程，甚至在不同的网络节点上。委托的目的是将处理某个任务的职责移交给另外一个组件， 以便发起委托的组件可以执行其他的处理、 或者有选择性地观察被委托的任务的进度， 以防需要执行额外的操作（如处理失败或者报告进度）。

- 弹性（与“可伸缩性”对照）：弹性意味着当资源根据需求按比例地减少或者增加时， 系统的吞吐量将自动地向下或者向上缩放， 从而满足不同的需求。系统需要具有可伸缩性， 以使得其可以从运行时动态地添加或者删除资源中获益。因此，弹性是建立在可伸缩性的基础之上的， 并通过添加自动的资源管理概念对其进行了扩充。

- 失败（和“错误”相对照）：失败是一种服务内部的意外事件， 会阻止服务继续正常地运行。失败通常会阻止对于当前的、 并可能所有接下来的客户端请求的响应。和错误相对照， 错误是意料之中的，并且针各种情况进行了处理（ 例如， 在输入验证的过程中所发现的错误）， 将会作为该消息的正常处理过程的一部分返回给客户端。而失败是意料之外的， 并且在系统能够恢复至（和之前）相同的服务水平之前，需要进行干预。这并不意味着失败总是致命的（fatal）， 虽然在失败发生之后， 系统的某些服务能力可能会被降低。错误是正常操作流程预期的一部分， 在错误发生之后， 系统将会立即地对其进行处理， 并将继续以相同的服务能力继续运行。失败的例子有： 硬件故障、 由于致命的资源耗尽而引起的进程意外终止，以及导致系统内部状态损坏的程序缺陷

- 隔离（和“遏制”相对照）：隔离可以定义为在时间和空间上的解耦。在时间上解耦意味着发送者和接收者可以拥有独立的生命周期—— 它们不需要同时存在，从而使得相互通信成为可能。通过在组件之间添加异步边界， 以及通过消息传递实现了这一点。在空间上解耦（定义为位置透明性）意味着发送者和接收者不必运行在同一个进程中。不管运维部门或者运行时本身决策的部署结构是多么的高效——在应用程序的生命周期之内，这一切都可能会发生改变。真正的隔离超出了大多数面向对象的编程语言中的常见的封装概念， 并使得我们可以对下述内容进行划分和遏制：状态和行为：它支持无共享的设计，并最大限度地减少了竞争和一致性成本（如通用伸缩性原则（Universal Scalability Law）中所定义的）；失败：它支持在细粒度上捕获、发出失败信号以及管理失败， 而不是将其扩散（cascade）到其他组件。
  组件之间的强隔离性是建立在明确定义的协议的通信之上的， 并支持解耦， 从而使得系统更加容易被理解、扩展、测试和演化。

- 位置透明性：弹性系统需要能够自适应， 并不间断地对需求的变化做出反应。它们需要优雅而高效地扩大或者缩减（部署）规模。极大地简化这个问题的一个关键洞察是：认识到我们一直都在处理分布式计算。无论我们是在一台单独的（具有多个独立 CPU，并通过快速通道互联（QPI）通信的）节点之上， 还是在一个（具有多台通过网络进行通信的独立节点的）机器集群之上运行我们的系统， 都是如此。拥抱这一事实意味着， 在多核心之上进行垂直缩放和在集群之上进行水平伸缩并没有什么概念上的差异。如果我们所有的组件都支持移动性， 而本地通信只是一项优化。那么我们根本不需要预先定义一个静态的系统拓扑和部署结构。可以将这个决策留给运维人员或者运行时， 让他（它）们其可以根据系统的使用情况来对其进行调整和优化。这种通过异步的消息传递实现的在空间上的（请参见隔离的定义）解耦， 以及将运行时实例和它们的引用解耦，就是我们所谓的位置透明性。位置透明性通常被误认为是“透明的分布式计算”， 然而实际上恰恰相反： 我们拥抱网络， 以及它所有的约束——如部分失败、 网络分裂、 消息丢失， 以及它的异步性和与生俱来的基于消息的性质，并将它们作为编程模型中的一等公民， 而不是尝试在网络上模拟进程内的方法调用（如 RPC、XA 等）。我们对于位置透明性的观点与 Waldo 等人著的 A Note On Distributed Computing 中的观点完全一致。

- 消息驱动（与“事件驱动”对照）：消息是指发送到特定目的地的一组特定数据， 事件是组件在达到了某个给定状态时所发出的信号。在消息驱动的系统中， 可寻址的接收者等待消息的到来， 并对消息做出反应， 否则只是休眠（即异步非阻塞地等待消息的到来）。而在事件驱动的系统中， 通知监听器被附加到了事件源， 以便在事件被发出时调用它们（指回调）。这也就意味着， 事件驱动的系统关注于可寻址的事件源， 而消息驱动的系统则着重于可寻址的接收者。消息可以包含编码为它的有效载荷的事件。由于事件消耗链的短暂性， 所以在事件驱动的系统中很难实现回弹性 ： 当处理过程已经就绪，监听器已经设置好， 以便于响应结果并对结果进行变换时， 这些监听器通常都将直接地处理成功或者失败， 并向原始的客户端报告执行结果。（这些监听器）响应组件的失败， 以便于恢复它（指失败的组件）的正常功能，而在另外一方面， 需要处理的是那些并没有与短暂的客户端请求捆绑在一起的， 但是影响了整个组件的健康状况的失败。

- 非阻塞的：在并发编程中， 如果争夺资源的线程并没有被保护该资源的互斥所无限期地推迟执行， 那么该算法则被认为是非阻塞的。在实践中， 这通常缩影为一个 API， 当资源可用时， 该 API 将允许访问该资源， 否则它将会立即地返回， 并通知调用者该资源当前不可用， 或者该操作已经启动了，但是尚未完成。某个资源的非阻塞 API 使得其调用者可以进行其他操作， 而不是被阻塞以等待该资源变为可用。此外，还可以通过允许资源的客户端注册， 以便让其在资源可用时，或者操作已经完成时获得通知。

- 协议：协议定义了在组件之间交换或者传输消息的方法与规范。协议由会话参与者之间的关系、 协议的累计状态以及允许发送的消息集所构成。这意味着， 协议描述了会话参与者在何时可以发送什么样的消息给另外一个会话参与者。协议可以按照其消息交换的形式进行分类， 一些常见的类型是：请求——响应模式、 重复的请求——响应模式（如 HTTP 中）、 发布——订阅模式、 以及（反应式）流模式（同时包含（动态地）推送和拉取）。和本地编程接口相比， 协议则更加通用， 因为它可以包含两个以上的参与者， 并且可以预见到消息交换的进展， 而接口仅仅指定了调用者和接收者之间每次一次的交互过程。需要注意的是， 这里所定义的协议只指定了可能会发送什么样的消息， 而不是它们应该如何被编码、解码（即编解码）， 而且对于使用该协议的组件来说，传输机制是透明的。

- 复制：在不同的地方同时地执行一个组件被称为复制。这可能意味着在不同的线程或者线程池、 进程、 网络节点或者计算中心中执行。复制提供了可伸缩性（传入的工作负载将会被分布发到跨组件的多个实例中） 以及回弹性 （传入的工作负载将会被复制到多个并行地处理相同请求的多个实例中）。这些方式可以结合使用， 例如， 在确保该组件的某个确定用户的所有相关事务都将由两个实例执行的同时， 实例的总数则又根据传入的负载而变化，（参见 弹性）。在复制有状态的组件时，必须要小心同步副本之间的状态数据，否则该组件的客户则需要知道同步的模式，并且还违反了封装的目的。通常，同步方案的选择需要在一致性和可用性之间进行权衡，如果允许被复制的副本可以在有限的时间段内不一致（最终一致性），那么将会得到最佳的可用性，同时，完美的一致性则要求所有的复制副本以一种步调一致（lock-step）的方式来推进它们的状态。在这两种“极端”之间存在着一系列的可能解决方案，所以每个组件都应该选择最适合于其需要的方式。

- 资源：组件执行其功能所依赖的一切都是资源， 资源必须要根据组件的需要而进行调配。这包括 CPU 的分配、 内存以及持久化存储以及网络带宽、 内存带宽、 CPU 缓存、 内部插座的 CPU 链接、 可靠的计时器以及任务调度服务、 其他的输入和输出设备、 外部服务（如数据库或者网络文件系统等）等等。所有的这些资源都必须要考虑到 弹性和回弹性 ， 因为缺少必需的资源将妨碍组件在被需要时发挥正常作用。

- 可伸缩性：一个系统通过利用更多的计算资源来提升其性能的能力， 是通过系统吞吐量的提升比上资源所增加的比值来衡量的。一个完美的可伸缩性系统的特点是这两个数字是成正比的。所分配的资源加倍也将使得吞吐量翻倍。可伸缩性通常受限于系统中所引入的瓶颈或者同步点， 参见 Amdahl 定律以及 Gunther 的通用可伸缩模型（ Amdahl’s Law and Gunther’s Universal Scalability Model）。

- 系统：系统为它的用户或者客户端提供服务。系统可大可小， 它们可以包含许多组件或者只有少数几个组件。系统中的所有组件相互协作，从而提供这些服务。在很多情况下， 位于相同系统中的多个组件之间，具有某种客户端——服务端的对应关系（例如，考虑一下，前端组件依赖于后端组件）。一个系统中共享着一种通用的回弹性模型， 意即， 某个组件的失败将会在该系统的内部得到处理， 并由一个组件委托给另外一个组件。如果系统中的某系列组件的功能、资源或者失败模型都和系统中的其余部分相互隔离， 那么将这一系列的组件看作是系统的子系统将更有利于系统设计。

- 用户：我们使用这个术语来非正式地指代某个服务的任何消费者，可以是人类或者其他服务。
